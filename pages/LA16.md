These definitions and theorems are adapted from [Linear Algebra and its Applications](https://www.cartagena99.com/recursos/alumnos/temarios/210609113348-Linear%20Algebra%20and%20its%20applications.pdf) by Lay, Lay and McDonald.


### 4.2 Null Spaces, Column Spaces and Linear Transformations


# --outlinebox
**Definition** The **null space** of an $m \times n$ matrix $A$, writen as $\text{Null } A$, is the set of all solutions of the homogeneous equation $A{\bf x} = {\bf 0}$. In set notation
$$\text{Null } A = \{ {\bf x} : {\bf x} \text{  is in } \mathbb{R}^n and  A{\bf x} = {\bf 0} \}$$
# --outlinebox


# --outlinebox
**Theorem 4.2** The null space of an $m \times n$ matrix $A$ is a subspace of $\mathbb{R}^n$. 
# --outlinebox


# --outlinebox
**Definition** The **column space** of an $m \times n$ matrix $A$, writen as $\text{Col } A$, is the set of all linear combinations of the columns in $A$. If 
$$ A = 
\begin{bmatrix}
{\bf a}_1 & \cdots & {\bf a}_n
\end{bmatrix}
$$ then 
$$\text{Col } A = \text{Span } \{ {\bf a}_1, \ldots, {\bf a}_n \}$$
# --outlinebox


# --outlinebox
**Theorem 4.3** The column space of an $m \times n$ matrix $A$ is a subspace of $\mathbb{R}^m$. 
# --outlinebox

# --outlinebox
**Definition** A **linear transformation** $T$ from a vector space $V$ into a vector space $W$ is a rule that assignes to each vector ${\bf x}$ in $V$ a unique vector $T({\bf x})$ in $W$, such that
- $T({\bf u} + {\bf v}) = T({\bf u}) + T({\bf v})$ for all ${\bf u}$, ${\bf v}$ in $V$;
 - $T(c{\bf u}) = cT({\bf u})$ for all scalars $c$ and all ${\bf u}$ in $V$.
# --outlinebox

The **kernel** (or **null space**) of such a $T$ is the set of all ${\bf u}$ in $V$ such that $T({\bf u}) = {\bf 0}$.  The **range** of $T$ is the set of all vectors in $W$ of the form $T({\bf x})$ for some value ${\bf x}$ in $V$. If $T$ happens to arise as a matrix transformation -- say, $T({\bf x}) = A{\bf x}$ for some matrix $A$ -- then the kernel and the range of $T$ are just the null space abd the column space of $A$.


**Example 8** Let $V$ be the vector space of all real-valued functions $f$ defined on an interval $\[a,b\]$ with the property that they are differentiable and their derivatives are continuous functions on $\[a,b\]$.  Let $W$ be the vector space $C\[a,b\]$ of all continuous functions on $\[a,b\]$, and let $D:V \rightarrow W$ be the transformation that changes $f$ in $V$ into its derivative $f'$.  In calculus, two simple differentiation rules are 
$$D(f+g) = D(f) + D(g)$$ and 
$$D(cf) = cD(f)$$ for functions $f$, $g$ and constant $c$.  So $D$ is a linear transformation.  The kernal of $D$ is the set of constant functions on $\[a,b\]$ and the range of $D$ is the set $W$ of all continuous functions on $\[a,b\]$.

**Example 9** The differential equation $$y'' + \omega^2 y = 0$$ where $\omega$ is a constant, is used to describe a variety of physical systems, such as the vibration of a weighted spring, the movement of a pendulum, and the voltage in an inductance-capacitance electrical circuit.  The sest of solutions is precisely the kernel of the linear transformation that maps a function $y=f(t)$ into the function $f''(t) + \omega^2f(t)$. Finding an explicit description of this vector space is a problem in differential equations.  The solution set turns out to be the space described in Exercies 19 from section 4.1.


[4.3 Linearly Independent Sets; Bases](/pages/LA17)
[Back to Index](/pages/andre)

